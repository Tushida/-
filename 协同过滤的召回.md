### 协同过滤进行召回

首先是一些工具函数：

这里先略过

其次是对于相似度矩阵的计算：

**1.文章相似性的计算：**（创建时间、点击时间、点击顺序）

这里主要基于**用户行为共现模式**，其核心思想是：如果两篇**文章经常被同一用户在相近时间点击**，则认为他们相似；这里还考虑了

1. 用户点击的时间权重
2. 用户点击的顺序权重
3. 文章创建的时间权重

输入数据：仅依赖用户-文章交互日志

相似度计算：

```python
                # 考虑文章的正向顺序点击和反向顺序点击    
                loc_alpha = 1.0 if loc2 > loc1 else 0.7
                # 位置信息权重，其中的参数可以调节
                loc_weight = loc_alpha * (0.9 ** (np.abs(loc2 - loc1) - 1))
                # 点击时间权重，其中的参数可以调节
                click_time_weight = np.exp(0.7 ** np.abs(i_click_time - j_click_time))
                # 两篇文章创建时间的权重，其中的参数可以调节
                created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))
                i2i_sim[i].setdefault(j, 0)
                # 考虑多种因素的权重计算最终的文章之间的相似度
                i2i_sim[i][j] += loc_weight * click_time_weight * created_time_weight / math.log(len(item_time_list) + 1)
```

**2.用户相似度计算**

这里我们使用基于用户的活跃度（点击次数）和用户的一个点击主题序列（高频词）

```python
 for item, user_time_list in tqdm(item_user_time_dict.items()):
        for u, click_time in user_time_list:
            user_cnt[u] += 1
            u2u_sim.setdefault(u, {})
            for v, click_time in user_time_list:
                u2u_sim[u].setdefault(v, 0)
                if u == v:
                    continue
                # 用户平均活跃度作为活跃度的权重，这里的式子也可以改善
                activate_weight = 100 * 0.5 * (user_activate_degree_dict[u] + user_activate_degree_dict[v])   
                u2u_sim[u][v] += activate_weight / math.log(len(user_time_list) + 1)
```

#### 基于物品的召回

这里的思想是：给用户召回与其历史文章相似的文章。

这里主要考虑三个权重：

（点击位置）考虑相似文章与历史点击文章顺序的权重

```python
0.9 ** (len(user_hist_items) - loc)
```

用户最近点击的物品（loc 值小）对应的相似物品 j 权重更高。

（考虑文章之间时间差）考虑文章创建时间的权重，也就是考虑相似文章与历史点击文章**创建时间差**的权重

```python
np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))
```

惩罚物品i和j的创建时间差异，差异越小，则权重越高（exp用于放大差异）

（文章内容相似度）考虑文章内容的相似度

```python
content_weight = 1.0
            if emb_i2i_sim.get(i, {}).get(j, None) is not None:
                content_weight += emb_i2i_sim[i][j]
            if emb_i2i_sim.get(j, {}).get(i, None) is not None:
                content_weight += emb_i2i_sim[j][i]
```

整体流程如下：

获取用户的历史点击文章列表，然后遍历该列表

​	对于每篇历史文章：

​		遍历与其最相似（embedding相似度和用户行为共现相似度）的TopK篇文章；针对这些文章，计算三个权重，最后聚合权重，得到排序的权重列表：

```python
item_rank[j] += created_time_weight * loc_weight * content_weight * wij
```

##### **分别使用emb相似度、用户共现行为相似度进行召回**

1、i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))

2、i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl','rb'))

召回结果评估：

```python
评估召回效果（若 metric_recall=True）：

metrics_recall：计算命中率（Hit Rate）或召回率（Recall），检查用户的最后一次点击是否在召回的Top-10列表中。

```

#### **基于用户的召回**

核心思想是给当前用户推荐相似用户的历史点击文章

利用一些关联规则来给用户可能点击的文章进行加权：这里采用了：1、**文章之间的相似度** 2、**文章创建的时间差**

3、**相对位置的总和**

代码逻辑：

首先根据该用户的ID获取其历史交互文章列表并去重：

```python
user_item_time_list = user_item_time_dict[user_id]
user_hist_items = set(i for i,t in user_item_time_list)
```

前面我们已经计算得到用户的相似度矩阵u2u_sim，这里我们需要取出TopK个相似用户的历史item列表，并进行加权相似性计算：

```python
for sim_u, wuv in sorted(u2u_sim[user_id].items(), key = lambba x : x[1],reverse = True)[:sim_user_topK]:# items()方法将--转为键值对列表，key值表示排序依据为每个元组的第二个元素
    #得到相似TopK个用户之后，接下来需要对这些用户的历史文章进行操作
    for i,click_time in user_item_time_dict[sim_u]:
        # 判断文章是否和相似用户的文章重复,初始化该文章的得分
        if(i in user_hist_itmes):
            continue
        items_rank.setdefault(i, 0)
        # 初始化上述提到的三个权重
        loc_weight = 1.0
        content_weight = 1.0
        created_time_weight = 1.0
        
        # 该文章与该用户看到历史文章的权重交互
        for loc, (j,click_time) in enumerate(user_item_time_list):
            # 点击时的相对位置权重（越靠前权重越高）
            loc_weight += 0.9**(len(user_item_time_list) - loc)
            # 内容相似性权重
            if emb_i2i_sim.get(i, {}).get(j, None) is not None:
                content_weight += emb_i2i_sim[i][j]
            if emb_i2i_sim.get(j, {}).get(i, None) is not None:
              	content_weight += emb_i2i_sim[j][i]
            # 创建时间差权重：计算所有创建时间差并累加
            created_time_weight += np.exp(0.8*np.abs(item_created_time_dict[i] - item_created_time_dict[j]))
     # 根据权重计算该文章的分数
     item_rank[i] = loc_weight * content_weight * created_time_weight * wuv
            
```

这里还需处理召回文章数量不足的情况：进行热度补全

```python
if len(items_rank) < recall_item_num:
    for i, item in enumerate(item_topk_click):
        if item in items_rank.items(): 
            continue
        items_rank[item] = - i - 100  # 给补充的文章一个较低的得分
        if len(items_rank) == recall_item_num:
            break
```

