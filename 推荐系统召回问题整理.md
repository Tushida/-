1. 协同过滤的核心思想？


​		利用用户-物品交互数据，通过相似用户和相似物品进行推荐，分为基于内存的协同过滤（User-CF、Item-CF）和基于模型的协同过滤（矩阵分解、神经网络）



​	2. 双塔模型？

- **用户塔（User Tower）**
  输入：用户特征（ID、历史行为、画像标签等）
  输出：用户向量（如128维稠密向量）

- **物品塔（Item Tower）**
  输入：物品特征（ID、类别、内容标签等）
  输出：物品向量（与用户向量同维度）

- 相似度计算

  - $$
    score(u,i)=u^Ti或者\frac{u^Ti}{||u||||i||}
    $$

    

3. youtubeDNN中，图中的video vector怎么得到的？模型的输入特征是某个用户点击过的视频和这个用户的query，这里的video vector应该只是这个用户点击过的视频的vector？

- **Video Vector是物品塔（Item Tower）的输出**，即所有视频（包括用户点击过的和其他候选视频）通过物品塔生成的嵌入向量。

- **用户点击过的视频的Vector**会被用于构建用户兴趣表征（即用户塔的输入），但这些视频的Vector本身仍然是物品塔生成的。

- **线上服务时**：所有视频的Vector会**预计算并存储**，用户塔生成用户向量后，通过近似最近邻搜索（ANN）召回相似Video Vector对应的视频。

  

4. 召回阶段正负样本如何构造？
   1. 正样本的构造：显示反馈数据，如用户存在明确的行为：点击、购买等，对不同的行为加权处理以反映用户偏好；序列行为建模：通过用户会话提取正样本，如短期内的连续点击行为

   2. 负样本构造：简单负样本：随机采样加热门打压；困难负样本：曝光未点击的物品（需要确认曝光位置是否显著）；同类别负样本：与正样本同类别但是未交互的物品

      

5. 为什么双塔不直接合并输入一个DNN

   若将用户和物品特征直接拼接输入单一DNN（非双塔结构），会导致以下问题：

   1. **线上推理效率低**：
      1. 合并模型需实时拼接用户和物品特征，无法离线预计算物品Embedding，导致召回阶段计算复杂度为 O(N)*O*(*N*)（N为物品数量）。
      2. 双塔模型通过预存物品Embedding，线上计算复杂度降至 O(1)*O*(1)（近似最近邻检索）。
   2. **扩展性差**：
      1. 新增物品需重新推理整个模型，而双塔只需生成新物品Embedding。
   3. **特征耦合风险**：
      1. 用户和物品特征在输入层强耦合，可能引入噪声干扰（如物品特征影响用户表征学习）。

   双塔的工程优势：

   - **离线预计算**：物品塔Embedding可提前生成，加速召回。
   - **灵活更新**：用户塔和物品塔可异步更新（如用户塔实时更新，物品塔每日更新）。

   

6. dssm做召回时遇到了哪些问题，做了哪些优化？

   负样本优化：难负例挖掘（Hard Negative Mining），纠偏策略

   特征工程：引入用户行为数据（用户兴趣建模），冷启动优化（迁移学习，Meta-learning，内容特征强化）

   模型结构：双塔改进，基于双塔的结构优化：https://zhuanlan.zhihu.com/p/17819433311

   工程优化：ANN检索加速（使用Faiss或SCANN优化向量检索效率），分片召回（分类/topic召回），模型轻量化（知识蒸馏：如BERT蒸馏双塔，模型剪枝/量化）

   

7. dssm做召回时模型训练的评价指标？

   1. 召回率：Recall@K，命中率：HR@K，AUC）+ 下游模型预估

      

8. 如何评价新增一路召回分支的效果？

   方案选取：模型问题（现有模型捕捉不到） + 采样差异（点击/关联采样）模型推理逻辑：直推 + 归纳

   问题排查：新增召回下发占比 + 互补性（线上下发情况） + 离线过拟合（采样） + 模型（参数问题，梯度丢失）+ 特征 参数 对齐问题 + 线上失败率 + 线上样本穿越 + 样本数据偏（采样偏）

   业务数据分析：明确新增召回分支的目标（提升覆盖率/多样性/长尾物品发现等），分析当前推荐系统的痛点与新分支要解决的问题，确定评估指标（召回率、覆盖率、新颖性等）

   技术方案调研：候选召回方法：（基于内容的召回（Content-based），协同过滤变种（ItemCF/UserCF改进版），向量召回（双塔模型、Graph Embedding等），实时行为召回（Session-based），知识图谱召回，热门/新颖/多样性召回策略），可行性评估：（数据可得性（需要哪些特征数据），计算资源需求，与现有系统的兼容性）

   

9. 推荐系统中常用的Embedding方法有哪些？

   word2vec是最经典的词向量embedding方式，基于word2vec思想，item2vec使用item向量代替词向量。这类方法无法处理网络化的数据，于是出现了大量Graph Embedding技术。

   DeepWalk使用用户行为序列构建物品关系图，然后通过随机游走生成新的序列数据，继而通过word2vec训练。DeepWalk可以看做序列embedding到Graph embedding的过度方法。

   Node2vec核心思想在于同质性与结构性的权衡。同质性指的图中距离近的节点应该尽量相似（倾向于DFS），结构性指图中节点所处结构位置相似的应该尽量相似（倾向于BFS）。Node2vec设置了跳转概率，使当前游走过程可能朝着更深的方向（同质性），或是返回之前的方向（结构性）。

   EGES（基于边信息的增强图Embedding）引入边信息作为物品embedding的补充信息，边信息可以是基于知识图谱获得的信息（这类信息包括特征信息）。EGES的方法是对Item及其特征一起进行embedding建模，最终得到的单个Item的embedding向量是该item及其特征的加权平均。EGES对缺少历史数据的Item更为亲切。

   

10. **fm和矩阵分解模型思想上的的异同点。**

    MF 是用use和item 的特征隐向量表示user 和 item 的特征，进而做相似度计算，用于item召回。

    FM 是用因子分解机来做特征的二阶交叉，进而预测user 和 item 的ctr概率，可用于召回或者排序阶段。

    相同点：MF可以理解为一种特殊的FM，即只有 uid 和 iid 的 FM模型，MF将这两类特征通过矩阵分解来达到 embedding 的目的。

    区别：FM使用了id 之外的特征，同时FM还做了矩阵积的优化，复杂度大幅降低。

    

11、怎么离线评价召回算法?

​		召回最直接的评估就是[召回率](https://zhida.zhihu.com/search?content_id=186544288&content_type=Article&match_order=1&q=召回率&zhida_source=entity)，也就是召回集里正样本的比例；也可以不同的召回算法+同一个[排序算法](https://zhida.zhihu.com/search?content_id=186544288&content_type=Article&match_order=1&q=排序算法&zhida_source=entity)，还是用排序之后的AUC和RMSE来评估。